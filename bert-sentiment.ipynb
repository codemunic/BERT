{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/6%20-%20Transformers%20for%20Sentiment%20Analysis.ipynb","metadata":{"id":"labDuOgxp0g3"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:43:36.068373Z","iopub.execute_input":"2021-05-26T13:43:36.068783Z","iopub.status.idle":"2021-05-26T13:43:36.075599Z","shell.execute_reply.started":"2021-05-26T13:43:36.068749Z","shell.execute_reply":"2021-05-26T13:43:36.074717Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torch\nimport random\n\nSEED = 1111\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True","metadata":{"id":"N4bayX_jpZXP","execution":{"iopub.status.busy":"2021-05-26T13:43:36.085840Z","iopub.execute_input":"2021-05-26T13:43:36.086283Z","iopub.status.idle":"2021-05-26T13:43:36.092057Z","shell.execute_reply.started":"2021-05-26T13:43:36.086244Z","shell.execute_reply":"2021-05-26T13:43:36.091078Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"id":"5i5ep2Wnp-Dw","execution":{"iopub.status.busy":"2021-05-26T13:43:36.131173Z","iopub.execute_input":"2021-05-26T13:43:36.131502Z","iopub.status.idle":"2021-05-26T13:43:36.504284Z","shell.execute_reply.started":"2021-05-26T13:43:36.131471Z","shell.execute_reply":"2021-05-26T13:43:36.503489Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"tokens = tokenizer.tokenize(\"What's going on?\")\n\nprint(tokens)","metadata":{"id":"VvEWRnsMqHG3","outputId":"6caaac0f-9fad-4d9b-84e7-55069a7f5750","execution":{"iopub.status.busy":"2021-05-26T13:43:36.505776Z","iopub.execute_input":"2021-05-26T13:43:36.506105Z","iopub.status.idle":"2021-05-26T13:43:36.512280Z","shell.execute_reply.started":"2021-05-26T13:43:36.506068Z","shell.execute_reply":"2021-05-26T13:43:36.510749Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"['what', \"'\", 's', 'going', 'on', '?']\n","output_type":"stream"}]},{"cell_type":"code","source":"cls_token_idx = tokenizer.cls_token_id\nsep_token_idx = tokenizer.sep_token_id\npad_token_idx = tokenizer.pad_token_id\nunk_token_idx = tokenizer.unk_token_id\n\nprint(cls_token_idx, sep_token_idx, pad_token_idx, unk_token_idx)","metadata":{"id":"HZlZhfGKqW1m","outputId":"021797e7-c251-4ff0-804d-badd3313c168","execution":{"iopub.status.busy":"2021-05-26T13:43:36.513892Z","iopub.execute_input":"2021-05-26T13:43:36.514359Z","iopub.status.idle":"2021-05-26T13:43:36.524510Z","shell.execute_reply.started":"2021-05-26T13:43:36.514318Z","shell.execute_reply":"2021-05-26T13:43:36.523531Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"101 102 0 100\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize(sentence):\n    tokens = tokenizer.tokenize(sentence) \n    tokens = tokens[:254-2]\n    return tokens","metadata":{"id":"psTC1BiYqkJ9","execution":{"iopub.status.busy":"2021-05-26T13:43:36.526411Z","iopub.execute_input":"2021-05-26T13:43:36.526794Z","iopub.status.idle":"2021-05-26T13:43:36.532757Z","shell.execute_reply.started":"2021-05-26T13:43:36.526753Z","shell.execute_reply":"2021-05-26T13:43:36.531852Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torchtext import data\n\nTEXT = data.Field(batch_first = True,\n                  use_vocab = False,\n                  tokenize = tokenize,\n                  preprocessing = tokenizer.convert_tokens_to_ids,\n                  init_token = cls_token_idx,\n                  eos_token = sep_token_idx,\n                  pad_token = pad_token_idx,\n                  unk_token = unk_token_idx)\n\nLABEL = data.LabelField()","metadata":{"id":"7vkoBToipdnY","execution":{"iopub.status.busy":"2021-05-26T13:43:36.536832Z","iopub.execute_input":"2021-05-26T13:43:36.537348Z","iopub.status.idle":"2021-05-26T13:43:36.545612Z","shell.execute_reply.started":"2021-05-26T13:43:36.537310Z","shell.execute_reply":"2021-05-26T13:43:36.544711Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n/opt/conda/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchtext import datasets\n\ntrain_data, valid_data = datasets.IMDB.splits(TEXT, LABEL)\n","metadata":{"id":"bnYOGjz8qxnp","execution":{"iopub.status.busy":"2021-05-26T13:43:36.548051Z","iopub.execute_input":"2021-05-26T13:43:36.548442Z","iopub.status.idle":"2021-05-26T13:49:42.982435Z","shell.execute_reply.started":"2021-05-26T13:43:36.548378Z","shell.execute_reply":"2021-05-26T13:49:42.981577Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"downloading aclImdb_v1.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:02<00:00, 29.1MB/s]\n/opt/conda/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Number of training examples: {len(train_data)}\")\nprint(f\"Number of validation examples: {len(valid_data)}\")","metadata":{"id":"kDwbxz3btrYw","outputId":"453a71cb-4623-4238-dfef-6709c459158c","execution":{"iopub.status.busy":"2021-05-26T13:49:42.984117Z","iopub.execute_input":"2021-05-26T13:49:42.984446Z","iopub.status.idle":"2021-05-26T13:49:42.993394Z","shell.execute_reply.started":"2021-05-26T13:49:42.984410Z","shell.execute_reply":"2021-05-26T13:49:42.992346Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Number of training examples: 25000\nNumber of validation examples: 25000\n","output_type":"stream"}]},{"cell_type":"code","source":"LABEL.build_vocab(train_data)","metadata":{"id":"wXu4uePBq6Ic","execution":{"iopub.status.busy":"2021-05-26T13:49:42.995445Z","iopub.execute_input":"2021-05-26T13:49:42.996149Z","iopub.status.idle":"2021-05-26T13:49:43.054762Z","shell.execute_reply.started":"2021-05-26T13:49:42.996113Z","shell.execute_reply":"2021-05-26T13:49:43.054149Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ntrain_iterator, valid_iterator = data.BucketIterator.splits(\n    (train_data, valid_data), \n    batch_size = BATCH_SIZE, \n    device = device)","metadata":{"id":"gpC8I72yrB1P","execution":{"iopub.status.busy":"2021-05-26T13:49:43.056077Z","iopub.execute_input":"2021-05-26T13:49:43.056451Z","iopub.status.idle":"2021-05-26T13:49:43.124364Z","shell.execute_reply.started":"2021-05-26T13:49:43.056415Z","shell.execute_reply":"2021-05-26T13:49:43.123372Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertModel\n\nbert = BertModel.from_pretrained('bert-base-uncased')","metadata":{"id":"vbKB5GoSrIGd","outputId":"cd049728-1938-4aae-8edf-54bb39ec692d","execution":{"iopub.status.busy":"2021-05-26T13:49:43.125912Z","iopub.execute_input":"2021-05-26T13:49:43.126548Z","iopub.status.idle":"2021-05-26T13:50:00.839036Z","shell.execute_reply.started":"2021-05-26T13:49:43.126503Z","shell.execute_reply":"2021-05-26T13:50:00.838223Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a091fed8f6ff418a947782b28cdb8e5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eccd1ef2a3684802889ddf72e96fe48a"}},"metadata":{}}]},{"cell_type":"code","source":"import torch.nn as nn\n\nclass BERTSentiment(nn.Module):\n    def __init__(self,\n                 bert,\n                 output_dim):\n        \n        super().__init__()\n        \n        self.bert = bert\n        \n        embedding_dim = bert.config.to_dict()['hidden_size']\n        \n        self.out = nn.Linear(embedding_dim, output_dim)\n        \n    def forward(self, text):\n        \n        #text = [batch size, sent len]\n                \n        embedded = self.bert(text)[1]\n                \n        #embedded = [batch size, emb dim]\n        \n        output = self.out(embedded)\n        \n        #output = [batch size, out dim]\n        \n        return output","metadata":{"id":"Pr4o0FUYrLof","execution":{"iopub.status.busy":"2021-05-26T13:50:00.840335Z","iopub.execute_input":"2021-05-26T13:50:00.840735Z","iopub.status.idle":"2021-05-26T13:50:00.846919Z","shell.execute_reply.started":"2021-05-26T13:50:00.840694Z","shell.execute_reply":"2021-05-26T13:50:00.845901Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"\nOUTPUT_DIM = 2\n\nmodel = BERTSentiment(bert,\n                     OUTPUT_DIM).to(device)","metadata":{"id":"XjDvjcHvuWKQ","execution":{"iopub.status.busy":"2021-05-26T13:50:00.848578Z","iopub.execute_input":"2021-05-26T13:50:00.849027Z","iopub.status.idle":"2021-05-26T13:50:04.983090Z","shell.execute_reply.started":"2021-05-26T13:50:00.848986Z","shell.execute_reply":"2021-05-26T13:50:04.982151Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'The model has {count_parameters(model):,} trainable parameters')","metadata":{"id":"k-FmHOXJupDk","outputId":"ebe0a20a-aeea-4d89-edb5-41b04d5aadcf","execution":{"iopub.status.busy":"2021-05-26T13:50:04.984482Z","iopub.execute_input":"2021-05-26T13:50:04.984806Z","iopub.status.idle":"2021-05-26T13:50:04.991577Z","shell.execute_reply.started":"2021-05-26T13:50:04.984773Z","shell.execute_reply":"2021-05-26T13:50:04.990788Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"The model has 109,483,778 trainable parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.optim as optim\nfrom transformers import AdamW, get_constant_schedule_with_warmup\n\noptimizer = AdamW(model.parameters(),lr=2e-5,eps=1e-6)\n\ndef get_scheduler(optimizer, warmup_steps):\n    scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)\n    return scheduler","metadata":{"id":"HLc1RwKfu2vb","execution":{"iopub.status.busy":"2021-05-26T13:50:04.993051Z","iopub.execute_input":"2021-05-26T13:50:04.993516Z","iopub.status.idle":"2021-05-26T13:50:10.276170Z","shell.execute_reply.started":"2021-05-26T13:50:04.993480Z","shell.execute_reply":"2021-05-26T13:50:10.275396Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss().to(device)","metadata":{"id":"BWYANetau4bp","execution":{"iopub.status.busy":"2021-05-26T13:50:10.277391Z","iopub.execute_input":"2021-05-26T13:50:10.277714Z","iopub.status.idle":"2021-05-26T13:50:10.288821Z","shell.execute_reply.started":"2021-05-26T13:50:10.277681Z","shell.execute_reply":"2021-05-26T13:50:10.288139Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#to calculate accuracy\n\ndef categorical_accuracy(preds, y):\n    max_preds = preds.argmax(dim = 1, keepdim = True)\n    correct = (max_preds.squeeze(1)==y).float()\n    return correct.sum() / len(y)","metadata":{"id":"_e5_wdpJvCIN","execution":{"iopub.status.busy":"2021-05-26T13:50:10.291760Z","iopub.execute_input":"2021-05-26T13:50:10.292017Z","iopub.status.idle":"2021-05-26T13:50:10.300956Z","shell.execute_reply.started":"2021-05-26T13:50:10.291993Z","shell.execute_reply":"2021-05-26T13:50:10.300032Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"max_grad_norm = 1\n\ndef train(model, iterator, optimizer, criterion, scheduler):\n    \n    \n    epoch_loss = 0\n    epoch_acc = 0\n    \n    model.train()\n    \n    for batch in iterator:\n\n        optimizer.zero_grad() # clear gradients first\n        torch.cuda.empty_cache() # releases all unoccupied cached memory \n        \n\n        text = batch.text\n        \n        label = batch.label\n        \n        predictions = model(text)\n        \n        loss = criterion(predictions, label)\n        \n        acc = categorical_accuracy(predictions, label)\n        #torch.nn.utils.clip_grad_norm_(optimizer, max_grad_norm)\n        loss.backward()\n        \n        optimizer.step()\n        scheduler.step()\n        \n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n        \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)","metadata":{"id":"NtzzMNTpvKv_","execution":{"iopub.status.busy":"2021-05-26T13:50:10.302366Z","iopub.execute_input":"2021-05-26T13:50:10.302809Z","iopub.status.idle":"2021-05-26T13:50:10.314200Z","shell.execute_reply.started":"2021-05-26T13:50:10.302767Z","shell.execute_reply":"2021-05-26T13:50:10.313196Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, iterator, criterion):\n    epoch_loss = 0\n    epoch_acc = 0\n    \n    model.eval()\n    \n    with torch.no_grad():\n    \n        for batch in iterator:\n\n            text = batch.text\n            label = batch.label\n                        \n            predictions = model(text)\n            \n            loss = criterion(predictions, label)\n                \n            acc = categorical_accuracy(predictions, label)\n            \n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n        \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)","metadata":{"id":"6fckvmrMvask","execution":{"iopub.status.busy":"2021-05-26T14:08:44.960623Z","iopub.execute_input":"2021-05-26T14:08:44.960987Z","iopub.status.idle":"2021-05-26T14:08:44.968680Z","shell.execute_reply.started":"2021-05-26T14:08:44.960954Z","shell.execute_reply":"2021-05-26T14:08:44.967592Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import time\n\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"id":"pbrfGoxUvdMe","execution":{"iopub.status.busy":"2021-05-26T13:50:10.325002Z","iopub.execute_input":"2021-05-26T13:50:10.325419Z","iopub.status.idle":"2021-05-26T13:50:10.333298Z","shell.execute_reply.started":"2021-05-26T13:50:10.325385Z","shell.execute_reply":"2021-05-26T13:50:10.332545Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import math\nN_EPOCHS = 3\ntrain_data_len = 25000\n\nwarmup_percent = 0.2\ntotal_steps = math.ceil(N_EPOCHS*train_data_len*1./BATCH_SIZE)\nwarmup_steps = int(total_steps*warmup_percent)\nscheduler = get_scheduler(optimizer, warmup_steps)\n\nbest_valid_loss = float('inf')\n\nfor epoch in range(N_EPOCHS):\n\n    start_time = time.time()\n    \n    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, scheduler)\n    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n    \n    end_time = time.time()\n\n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n    \n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'bert-nli.pt')\n    \n    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')","metadata":{"id":"dPGvt8Eyvfhc","outputId":"f15947a5-353f-4450-a7e6-e276adff928b","execution":{"iopub.status.busy":"2021-05-26T14:11:39.476743Z","iopub.execute_input":"2021-05-26T14:11:39.477289Z","iopub.status.idle":"2021-05-26T15:05:58.648839Z","shell.execute_reply.started":"2021-05-26T14:11:39.477249Z","shell.execute_reply":"2021-05-26T15:05:58.647326Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Epoch: 01 | Epoch Time: 18m 5s\n\tTrain Loss: 0.190 | Train Acc: 92.78%\n\t Val. Loss: 0.235 |  Val. Acc: 90.65%\nEpoch: 02 | Epoch Time: 18m 6s\n\tTrain Loss: 0.132 | Train Acc: 95.39%\n\t Val. Loss: 0.244 |  Val. Acc: 91.61%\nEpoch: 03 | Epoch Time: 18m 6s\n\tTrain Loss: 0.069 | Train Acc: 97.76%\n\t Val. Loss: 0.260 |  Val. Acc: 91.63%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}